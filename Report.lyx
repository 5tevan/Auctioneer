#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Predicting the Outcome of Online Penny Auctions Using Learning Algorithms
\end_layout

\begin_layout Author
Parsana Pillay, Stephen Rebstock, Stevan Clement
\end_layout

\begin_layout Date
December 13, 2012
\end_layout

\begin_layout Abstract
In this report we investigate the application of learning algorithms to
 online penny auctions for predicting the results of bids on low valued
 items such as gift cards and voucher bids.
 We first construct several methods to approach the issue of predicting
 outcomes of bids and user strategies.
 We then analyse the effectiveness of these methods using data collected
 from a popular penny auction website, Quibids.
 The relation between methods and their performance is discussed.
\end_layout

\begin_layout Section*
Problem
\end_layout

\begin_layout Standard
A penny auction is a type of auction where each participant pays a fixed
 price in order to place an incremental bid on an item.
 After each new bid is placed a timer is reset to a specific amount based
 on how long the auction has been going.
 At the expiration of the timer the auction ends and the last participant
 to bid is awarded the item for the current price.
 If a auction as been active for a certain time Quibids dose not display
 the auction to new users.
 This type of auction can be extremely profitable for the auctioneer as
 they are paid both the final item fee and the fees from each bid placed
 in the auction.
 The incentive to participate in this type of auction is the chance to pay
 a significantly lower amount than the retail price of an item.
\end_layout

\begin_layout Standard
There are a number of penny auction sites on the web.
 We choose the popular Quibids
\begin_inset Foot
status open

\begin_layout Plain Layout
http://quibids.com/
\end_layout

\end_inset

 site to collect our data from.
 On Quibids each bid costs 0.60 USD and increments the total price by 0.01
 USD.
 The problem we face is how to win an auction using the lowest possible
 number of bids.
 In this type of auction the final item price is only a fraction of the
 total amount the winner must pay, denoted by 
\begin_inset Formula 
\[
\mathtt{cost=(totalBids}*\mathtt{biddingFee)+finalItemCost+additionalCharges}
\]

\end_inset

Each of the other participants must pay for the bids they placed, even though
 they lost the auction and gained nothing.
 
\end_layout

\begin_layout Standard
There are a few other factors for the special case of Quibids auctions.
 There is a shipping cost of 9.50 USD and a transaction fee of 1.99 USD.
 The main difference between Quibids and other penny auction sites, such
 as the former top auction site Swoopo
\begin_inset Foot
status open

\begin_layout Plain Layout
http://www.swoopo.com/
\end_layout

\end_inset

, is the buy it now feature included on Quibids.
 When using this feature you can use the amount you paid for all the bids
 you have placed in a particular auction to pay the cost of the item.
 The price Quibids sets for items tends to be higher than in shopping sites
 or department stores.
 Additionally, the winner must pay the shipping and transaction fees.
 Quibids sets limits to the number of auctions you can win in a month and
 places a cap on the dollar amount of your total winnings.
 There is also a time limit on claiming your price.
 Thus a winner of an auction who does not claim their prize within a week
 loses all the money they spent on the auction.
\end_layout

\begin_layout Standard
In this project we try to solve this problem using various methods to predict
 when an auction is ending and a when winning bid will occur.
\end_layout

\begin_layout Section*
Literature Survey
\end_layout

\begin_layout Standard
Although online auctions are mentioned extensively in the literature, there
 are few papers addressing the specific problem of online penny auctions,
 a particular subset of bidding fee auctions.
 Bidding fee auctions are a type of English auction, where the price increases
 and the identity of each bidder is disclosed to all other bidders.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Coppinger:1980"

\end_inset

 looks at the performance of three different auctions.
 Dutch auctions, where bidding starts at the highest possible price which
 then decreases until someone bids, at which point the item is sold, a sealed
 bid auction, where everyone submits a sealed price and the highest price
 wins, and English auctions.
 The English Auction, the only auction where people bid against one another
 in a competitive manner, results in prices at or above the optimal price
 of the item.
 The other two auction types result in prices at or below the optimal value.
\end_layout

\begin_layout Standard
The earliest mention of the bidding fee auction model occurs in 
\begin_inset CommandInset citation
LatexCommand cite
key "Shubik:1971"

\end_inset

 where two bidders are set against each other in order to gain a one dollar
 bill.
 They must both pay whatever they bid, and the winner is given one dollar.
 The article explains how this process ends in a war of attrition resulting
 in participants making irrational decisions and an overall large profit
 for the auctioneer.
 A more recent paper 
\begin_inset CommandInset citation
LatexCommand cite
key "Hinnosaar:2010"

\end_inset

 attempts to model penny auctions and declares them to be unpredictable
 due to high variance of outcomes and unbounded revenue to the seller.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "Mittal:2010"

\end_inset

 it is shown that although we cannot predict user strategy, as it is too
 random for game theory, it is possible to predict profit from auctions.
 User strategy is mentioned again in 
\begin_inset CommandInset citation
LatexCommand cite
key "Caldara:2010"

\end_inset

, outlining that bidding strategies of each user involved in the auction
 affect the result of the auction.
 There are bidders who act irrationally and aggressive in the auctions and
 inexperienced bidders who drop out too quickly.
 The paper finishes by stating that auctions where the majority of users
 employ sophisticated strategies are far more predictable than those with
 irrational or novice strategies.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang:2012"

\end_inset

 remarks that novice users often radically overbid, but retained users often
 learn quickly and begin to minimize their losses.
 A penny auction site's survival then relies on attracting new inexperienced
 bidders who will lose money.
 This paper remarks that the key to learning understanding penny auctions
 is to focus on learning and strategic sophistication done by bidders.
 However, while focusing on the economics 
\begin_inset CommandInset citation
LatexCommand cite
key "EStix:2012"

\end_inset

 finds that for Quibids, most of the sites earnings come from experienced
 bidders.
 Quibids makes money due to the auctioning of its voucher bids, which we
 plan to study in this paper.
\end_layout

\begin_layout Standard
Bidding strategies are again mentioned in 
\begin_inset CommandInset citation
LatexCommand cite
key "JStix:2012"

\end_inset

.
 This study shows that 88% of auctions are won bidders whose strategy is
 to bid persistently throughout the auction.
 There are two types of persistent bidders: bidders who constantly bid during
 their time participating in an auction and bidders who alternate between
 constantly bidding and infrequently bidding as the auction goes on.
 Auctions usually end on average 30 bids after the last persistent bidder
 has left or with the last persistent bidder winning.
 Another important point is that 60% of auctions had the following pattern
 in the last 10 bids: a single bid at almost 0 seconds and a number of bids
 immediatly following that single bid.
\end_layout

\begin_layout Standard
Other auction sites are discussed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Ockenfels:2002"

\end_inset

.
 Specifically, user strategy based on bid timing for Amazon and eBay.
 As auction experience is gained by a bidder on these sites incremental
 bidding decreases and last minute bidding, known as auction sniping, increases.
 This has the effect of changing these sites into sealed bid auctions.
 If everyone submits a bid last minute, the highest bid will win and it
 will be impossible to react to another userâ€™s bid.
 Quibids avoids this problem by increasing the auction clock after every
 bid.
\end_layout

\begin_layout Standard
End auction prices on the now bankrupt site Swoopo are discussed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Nanney:2010"

\end_inset

 where game theory is used to determine a geometric distribution of penny
 auction end points that give a specific value for an auction item.
 Quibids Reports
\begin_inset Foot
status open

\begin_layout Plain Layout
http://www.quibidsreport.com/
\end_layout

\end_inset

, a subscription based service, shows a similar distribution for auction
 endings.
 Another interesting in site from this paper is to maximize profits auction
 sites such as Swoopo maintain a ratio of auctions to currently active users.
 The ratio is one auction for every thirty three users.
\end_layout

\begin_layout Standard
The most cited paper on penny auctions 
\begin_inset CommandInset citation
LatexCommand cite
key "Augenblick:2009"

\end_inset

 also discusses Swoopo.
 The paper notes that bidder experience is most important for minimizing
 expected loss.
 Despite the extremely lucrative appearance of penny auction for an auction
 host, it turns out that half of the auctions result in a loss for the auction
 site, due to the total price of the item plus all revenue from the bids
 often being less than the cost of the item.
 However, an auction site still makes an average profit of 50% of the item
 cost on all items.
 The paper points out that the end price of an auction is a function of
 the total number of users and total number of active auctions.
\end_layout

\begin_layout Standard
End prices of standard auctions are predicted in 
\begin_inset CommandInset citation
LatexCommand cite
key "Ghani:2004"

\end_inset

, and although penny auctions are very different from English auctions,
 also known as an open ascending price auctions, some of the features used
 in the analysis for this paper looked promising for penny auctions.
 Notably, the use of binary classification for eBay
\begin_inset Foot
status open

\begin_layout Plain Layout
http://www.ebay.com/
\end_layout

\end_inset

 auctions could prove to be an excellent tool for our work with penny auctions.
\end_layout

\begin_layout Section*
Approach and Rationale
\end_layout

\begin_layout Standard
The problem of predicting when to place a bid such that it will be a winning
 bid is a difficult problem to approach.
 After reviewing the literature we decided that it may be possible to predict
 the end with some degree of accuracy above random chance.
 Collecting the data and manipulating it took the majority of the time as
 we were unable to locate any free data sets for sites dealing with penny
 auctions.
 We wrote our own scraping programs to gather data from the website Quibids
 Insider
\begin_inset Foot
status open

\begin_layout Plain Layout
http://quibidsinsider.com/
\end_layout

\end_inset

 because it allowed us to access auctions from the American version of Quibids,
 featuring far more auctions than the Canadian site, without using a proxy
 server.
 Our programs were distributed throughout the undergraduate laboratories
 and operated using requests mimicking the original site's AJAX functionality
 to reduce the site load while collecting data.
\end_layout

\begin_layout Standard
Once the data had been acquired we manipulated it further to extract and
 expand features to create data sets for each of our hypotheses.
 This expansion is discussed below in the Experimental Design.
 As we were testing to see whether or not we could successful prediction
 results from penny auction data, a lot of our approach was the tests we
 used in our experiments.
\end_layout

\begin_layout Standard
We picked our hypotheses based on what data we considered useful for winning
 auctions.
 The main points covered are: if a next bid will win, if a user will win,
 and what the end price of the auction will be.
 If we can successfully predict these points, building a bot to win auctions
 would be a possible next step.
\end_layout

\begin_layout Section*
Plan
\end_layout

\begin_layout Standard
Our goal for this project is to show that penny auctions have enough structure
 that a learning algorithm will be able to make decent predictions on certain
 aspects of auction outcomes.
 The following hypotheses were constructed with this in mind.
\end_layout

\begin_layout Subsection*
Hypotheses
\end_layout

\begin_layout Enumerate
Given n bids, it is possible to predict whether the next bid will be a winning
 or losing bid.
 We are testing whether a bid history can provide a recognizable ending
 or continuing pattern for an auction.
\end_layout

\begin_layout Enumerate
Given a user in an auction, it is possible to predict whether this user
 will win.
 Users with specific bidding behaviours are more likely to win than others.
 We observed that often auctions end with many bidders still willing to
 bid believing someone else will bid.
\end_layout

\begin_layout Enumerate
Given a particular auction state, it is possible to predict the end price
 of the auction.
 This is similar to the first hypothesis, but uses regression instead of
 classification for more complete information about the final price.
\end_layout

\begin_layout Subsection*
Experimental Design
\end_layout

\begin_layout Standard
We used Mlpy 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/abs-1202-6548"

\end_inset

 to provide a framework for testing our hypotheses.
 Mlpy is an open source machine learning library written in Python providing
 functionality for regression, classification, and clustering which allowed
 us to run a variety of algorithms against our data sets.
 Making decisions about feature extraction and engineering was going to
 be an important part of getting decent results.
 The following features were used for each hypothesis:
\end_layout

\begin_layout Enumerate
For our X matrix we populated the row of features with a history of the
 previous 9 bids.
 Each bid included information about price at the time of the bid, amount
 of time left in the auction timer when the bid was placed, the time and
 date of the bid (auction sites are more popular at certain points in the
 day), the hour of the bid, the value of the item (we used only voucher
 bids and gift cards, so we could easily tell the value based on the item's
 name), whether or not it is a gameplay (some auctions have a gameplay feature
 to allow the auction winner to win extra bids), whether or not the item
 is a voucher bid, the number of bids in the last {5, 1, 1/6} minutes, and
 the time since the last bid.
 Our Y matrix was a binary classification matrix of whether or not the bid
 after those 9 bids won the auction.
\end_layout

\begin_layout Enumerate
For our X matrix we populated the row of features with the total bids a
 user had made in an auction, the value of the item, the hour of the auction,
 whether or not it is a gameplay, whether or not the item is a voucher bid,
 the total bids a user had made on all auctions in our database, when the
 user started bidding in an auction, when the user had finished bidding
 in an auction, and their average time between bids.
 Our Y matrix was a binary classification matrixof whether or not a user
 won the auction.
\end_layout

\begin_layout Enumerate
Using the same features as the first hypothesis we created an X matrix of
 a bid history of 9 bids.
 Our Y matrix was a matrix of final auction prices.
\end_layout

\begin_layout Standard
We first created a database of all our auction information.
 We had collected 30240 bids spanning 2421 auctions with 4551 different
 users.
 Each of our test matrices included 2000 random examples from this dataset.
\end_layout

\begin_layout Standard
Our first two hypotheses were tested using the following included functions
 for classification:
\end_layout

\begin_layout Itemize

\series bold
Large Linear Classification
\series default
 allows use of the LIBLINEAR library's 
\begin_inset CommandInset citation
LatexCommand cite
key "LIBLINEAR"

\end_inset

 different solvers.
 We also use the weight functionality to assign higher weights to winning
 bids in an attempt to separate their importance from non-winning bids.
\end_layout

\begin_layout Itemize

\series bold
k-means
\series default
 uses iterative partitioning to separate data into 
\shape italic
k
\shape default
 clusters.
\end_layout

\begin_layout Itemize

\series bold
Classification Trees
\series default
 are a type of decision tree learning based on predicting a class to which
 a piece of data belongs.
 This works by splitting the data into a tree model based on recursive partition
ing.
\end_layout

\begin_layout Itemize

\series bold
Kernel Fisher Discriminant Classification
\series default
 was the only kernel method we used.
 It is a kernelized version of linear discriminant analysis.
 Both Polynomial kernels and Gaussian kernels were tested.
\end_layout

\begin_layout Itemize

\series bold
Maximum Likelihood Classification
\series default
 calculates a Bayesian probability function which judges how likely a piece
 of data is to belong to a certain class.
\end_layout

\begin_layout Standard
On the third hypothesis we used the following tests for regression:
\end_layout

\begin_layout Itemize

\series bold
Ordinary Least Squares
\series default
 minimizes the sum of the squares of the errors to fit a hyperplane to data.
\end_layout

\begin_layout Itemize

\series bold
Ridge Regression
\series default
 is like least squares except it penalizes the size of regression coefficients.
\end_layout

\begin_layout Itemize

\series bold
Partial Least Squares
\series default
 is similar to least squares except it is better against noisy data sets
 as the data is first decomposed into a lower dimensional space.
\end_layout

\begin_layout Section*
Results
\end_layout

\begin_layout Section*
Evaluation
\end_layout

\begin_layout Standard
What we think it means.
\end_layout

\begin_layout Section*
Conclusion: Lessons Learned
\end_layout

\begin_layout Standard
Over the course of the project a lot of knowledge was gained about the problem
 domain.
 We learned that it is probably a bad idea to play penny auctions, as they
 are very close to gambling and highly unpredictable due to irrational human
 behaviour.
\end_layout

\begin_layout Standard
We learned a lot about scraping web sites for content.
 We initially ran into some trouble with placing too much load on the site
 we were scraping and were contacted by its web hosting company.
 After that we rewrote our code to reduce and distribute the amount of requests
 we were making and had no further problems gathering our data.
\end_layout

\begin_layout Standard
We had some ideas for further work on the topic.
 It would be interesting to extend upon our project using the information
 we gathered to create a classification algorithm.
 This would allow us to classifying different users to decide whether it
 is worth it to bid against the remaining bidders.
 
\end_layout

\begin_layout Standard
We didn't have a chance to try our predictions in the wild due to time and
 money constraints, but this would have been fun.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "references"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
